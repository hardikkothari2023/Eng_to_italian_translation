{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq Recurrent Translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "\n",
    "root_folder='.'\n",
    "data_folder_name='data'\n",
    "train_filename='ita.txt'\n",
    "\n",
    "DATA_PATH = os.path.abspath(os.path.join(root_folder, data_folder_name))\n",
    "train_filenamepath = os.path.abspath(os.path.join(DATA_PATH, train_filename))\n",
    "\n",
    "train_path = DATA_PATH\n",
    "test_path = DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "INPUT_COLUMN = 'input'\n",
    "TARGET_COLUMN = 'target'\n",
    "TARGET_FOR_INPUT = 'target_for_input'\n",
    "NUM_SAMPLES = 100000\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 1024 # Number of cells in the hidden recurrent layers\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    w = re.sub(r\"([?.!,])\", r\" \\1 \", w) \n",
    "\n",
    "    # Replacement of unwanted characters with a space\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", w)\n",
    "\n",
    "    w = re.sub(r'[\" \"]+', \" \", w) # Removal of consecutive spaces\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading the dataset\n",
    "Loading the dataset into a Pandas DataFrame and applying preprocessing functions on it in the Input and Target columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     input          target\n",
      "42  Do it.      Lo faccia.\n",
      "43  Do it.      La faccia.\n",
      "44  Do it.         Fatelo.\n",
      "45  Do it.         Fatela.\n",
      "46  Go on.     Vai avanti.\n",
      "47  Go on.       Continua.\n",
      "48  Go on.       Continui.\n",
      "49  Go on.     Continuate.\n",
      "50  Go on.    Vada avanti.\n",
      "51  Go on.  Andate avanti. \n",
      "\n",
      "['hi . ', 'hi . ', 'run ! ', 'run ! ', 'run ! ']\n",
      "['ciao !  <eos>', 'ciao .  <eos>', 'corri !  <eos>', 'corra !  <eos>', 'correte !  <eos>']\n",
      "['<sos> ciao ! ', '<sos> ciao . ', '<sos> corri ! ', '<sos> corra ! ', '<sos> correte ! ']\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset: sentence in English, sentence in Italian\n",
    "df = pd.read_csv(\n",
    "    train_filenamepath,\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[INPUT_COLUMN, TARGET_COLUMN],\n",
    "    usecols=[0,1],\n",
    "    nrows=NUM_SAMPLES\n",
    ")\n",
    "\n",
    "print(df.iloc[42:52], '\\n')\n",
    "\n",
    "# Preprocessing of Input data\n",
    "input_data = df[INPUT_COLUMN].apply(lambda x : preprocess_sentence(x)).tolist()\n",
    "\n",
    "# Preprocessing of Target data with the addition of the end-of-sentence token\n",
    "target_data_eos = df[TARGET_COLUMN].apply(lambda x : preprocess_sentence(x)+ ' <eos>').tolist()\n",
    "\n",
    "# Preprocessing of Target data with the addition of the start-of-sentence token\n",
    "target_data_sos = df[TARGET_COLUMN].apply(lambda x : '<sos> '+ preprocess_sentence(x)).tolist()\n",
    "\n",
    "print(input_data[:5])\n",
    "print(target_data_eos[:5])\n",
    "print(target_data_sos[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tokenization\n",
    "Converting sequences of words into sequences of integers enables models to operate on texts.\n",
    "In this example, two tokenizers are used, leveraging the Keras Tokenizer object,\n",
    "one for input sequences and one for target sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length:  9 \n",
      "\n",
      "do it . \n",
      "[16, 6, 1]\n"
     ]
    }
   ],
   "source": [
    "# The Tokenizer is constructed with filters='' to prevent the removal of punctuation characters present. \n",
    "# By default, Keras adds a series of standard filters, \n",
    "# which remove the following characters: !\"#$%&()*+,-./:;<=>?@[]^_`{|}~\\t\\n\"\n",
    "tokenizer_inputs = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
    "\n",
    "# Adapting the Tokenizer to the input texts\n",
    "tokenizer_inputs.fit_on_texts(input_data)\n",
    "\n",
    "# Transformation from sequences of words to sequences of numbers\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_data)\n",
    "\n",
    "# Maximum length in input sequences\n",
    "input_max_len = max(len(s) for s in input_sequences)\n",
    "print('Maximum length: ', input_max_len, '\\n')\n",
    "\n",
    "# Example of a sequence of words transformed into a sequence of numbers\n",
    "print(input_data[42])\n",
    "print(input_sequences[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Target Length:  20 \n",
      "\n",
      "Target sentence with end-of-sentence token (eos): lo faccia .  <eos>\n",
      "Target sequence with end-of-sequence token (eos): [23, 187, 1, 2]\n",
      "Target sentence with end-of-sentence token (eos): <sos> lo faccia . \n",
      "Target sequence with end-of-sequence token (eos): [3, 23, 187, 1]\n"
     ]
    }
   ],
   "source": [
    "# Tokenization of the targets\n",
    "tokenizer_outputs = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')\n",
    "tokenizer_outputs.fit_on_texts(target_data_eos)\n",
    "tokenizer_outputs.fit_on_texts(target_data_sos)\n",
    "\n",
    "# Transformation of the texts into sequences of integers\n",
    "target_sequences_eos = tokenizer_outputs.texts_to_sequences(target_data_eos)\n",
    "target_sequences_sos = tokenizer_outputs.texts_to_sequences(target_data_sos)\n",
    "\n",
    "# Maximum length of target sequences\n",
    "target_eos_max_len = max(len(s) for s in target_sequences_eos)\n",
    "print('Max Target Length: ', target_eos_max_len, '\\n')\n",
    "\n",
    "print('Target sentence with end-of-sentence token (eos):', target_data_eos[42])\n",
    "print('Target sequence with end-of-sequence token (eos):', target_sequences_eos[42])\n",
    "print('Target sentence with end-of-sentence token (eos):', target_data_sos[42])\n",
    "print('Target sequence with end-of-sequence token (eos):', target_sequences_sos[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Creation of vocabularies\n",
    "From the previously created tokenizers, we can derive their respective vocabularies\n",
    "to map a word to an index (word2idx) and to map an index to a word (idx2word)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6234 unique input tokens.\n",
      "Found 13559 unique output tokens.\n"
     ]
    }
   ],
   "source": [
    "# Retrieval of word indices for the input vocabulary\n",
    "word2idx_inputs = tokenizer_inputs.word_index\n",
    "print('Found %s unique input tokens.' % len(word2idx_inputs))\n",
    "\n",
    "# Retrieval of word indices for the output vocabulary\n",
    "word2idx_outputs = tokenizer_outputs.word_index\n",
    "print('Found %s unique output tokens.' % len(word2idx_outputs))\n",
    "\n",
    "# Data structures to retrieve a particular word given its index\n",
    "idx2word_inputs = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_outputs = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Padding of sentences\n",
    "Adding null (zero) values to the end of each sentence to make all sentences the same length. Otherwise, it wouldn't be possible to train the model on multiple examples at once (batch training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence [16, 6, 1]\n",
      "encoder_inputs.shape: (100000, 9)\n",
      "encoder_inputs[0]: [16  6  1  0  0  0  0  0  0]\n",
      "\n",
      "Target sequence with <sos> (start-of-sequence) token [3, 23, 187, 1]\n",
      "decoder_inputs[0]: [  3  23 187   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "decoder_inputs.shape: (100000, 20)\n",
      "\n",
      "Target sequence with <sos> (start-of-sequence) token [23, 187, 1, 2]\n",
      "decoder_target[0]: [ 23 187   1   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0]\n",
      "decoder_target.shape: (100000, 20)\n"
     ]
    }
   ],
   "source": [
    "# Padding of input sentences\n",
    "encoder_inputs = pad_sequences(input_sequences, maxlen=input_max_len, padding='post')\n",
    "print(\"Input sequence\", input_sequences[42])\n",
    "print(\"encoder_inputs.shape:\", encoder_inputs.shape)\n",
    "print(\"encoder_inputs[0]:\", encoder_inputs[42])\n",
    "print('')\n",
    "\n",
    "# Padding of target sentences with start-of-sequence token (sos)\n",
    "decoder_inputs = pad_sequences(target_sequences_sos, maxlen=target_eos_max_len, padding='post')\n",
    "print(\"Target sequence with <sos> (start-of-sequence) token\", target_sequences_sos[42])\n",
    "print(\"decoder_inputs[0]:\", decoder_inputs[42])\n",
    "print(\"decoder_inputs.shape:\", decoder_inputs.shape)\n",
    "print('')\n",
    "\n",
    "# Padding of target sentences with end-of-sequence token (eos)\n",
    "decoder_targets = pad_sequences(target_sequences_eos, maxlen=target_eos_max_len, padding='post')\n",
    "print(\"Target sequence with <sos> (start-of-sequence) token\", target_sequences_eos[42])\n",
    "print(\"decoder_target[0]:\", decoder_targets[42])\n",
    "print(\"decoder_target.shape:\", decoder_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Dataset creation\n",
    "Using the tf.data library to manage the dataset to be used.\n",
    "Batches of examples will be created and utilized during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Definition of the dataset\n",
    "# [from_tensor_slices] allows retrieving batches\n",
    "# of examples from the reference datasets.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((encoder_inputs, decoder_inputs, decoder_targets))\n",
    "\n",
    "# Setting up random sampling of examples in batches of [BATCH_SIZE] from the available ones\n",
    "dataset = dataset.shuffle(len(input_data)).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Implementation of a Recurrent Encoder-Decoder model\n",
    "The model can be represented through its three main components: encoder, encoded vector, decoder:\n",
    " \n",
    "    \n",
    "* **encoder**: Based on a recurrent layer, it receives a word from the input sequence in the form of a numeric token for each time step, producing an output and a state for each time step. The state at each time step t is used at time step t+1 along with the input related to time step t+1.\n",
    "* **encoder vector**: It is the state produced as output by the recurrent layers after processing the entire input sequence. During training, the network will strive to produce the best possible information so that the subsequent decoder block can perform its job optimally.\n",
    "* **decoder**: Based on a recurrent layer like the encoder block. It takes the encoder vector as input and produces the output representing the probability corresponding to each token in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.LSTM(hidden_dim, return_sequences=True, return_state=True)\n",
    "\n",
    "    def call(self, input_sequence, states):\n",
    "        embed = self.embedding(input_sequence)\n",
    "        output, state_h, state_c = self.lstm(embed, initial_state=states)\n",
    "        return output, state_h, state_c\n",
    "\n",
    "    def init_states(self, batch_size):\n",
    "        # Initialization of the state for the recurrent cells\n",
    "        return (tf.zeros([batch_size, self.hidden_dim]),\n",
    "                tf.zeros([batch_size, self.hidden_dim]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.LSTM(hidden_dim, return_sequences=True, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, input_sequence, state):\n",
    "        embed = self.embedding(input_sequence)\n",
    "        lstm_out, state_h, state_c = self.lstm(embed, state)\n",
    "        logits = self.dense(lstm_out)\n",
    "        return logits, state_h, state_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, an encoder and a decoder are instantiated, and their functionalities are tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6, 1024)\n",
      "(1, 8, 13560)\n"
     ]
    }
   ],
   "source": [
    "# Length of the input and output vocabularies\n",
    "num_words_inputs = len(word2idx_inputs) + 1  # +1 because the indices are 1-based\n",
    "num_words_output = len(word2idx_outputs) + 1\n",
    "\n",
    "encoder = Encoder(num_words_inputs, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "initial_state = encoder.init_states(1)\n",
    "\n",
    "# Call to the encoder for testing\n",
    "test_encoder_output = encoder(tf.constant([[1, 23, 4, 5, 0, 0]]), initial_state)\n",
    "print(test_encoder_output[0].shape)\n",
    "\n",
    "decoder = Decoder(num_words_output, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "de_initial_state = test_encoder_output[1:]\n",
    "\n",
    "# Call to the decoder for testing\n",
    "test_decoder_output = decoder(tf.constant([[1, 3, 5, 7, 9, 0, 0, 0]]), de_initial_state)\n",
    "print(test_decoder_output[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function and metrics\n",
    "Definition of a custom cost function to avoid considering the padding values (0s) when calculating the error. Similar approach for calculating the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(targets, logits):\n",
    "    crossentropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    # Masking of values equal to 0, used for padding\n",
    "    mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
    "    mask = tf.cast(mask, dtype=tf.int64)\n",
    "    # Error calculation\n",
    "    loss = crossentropy(targets, logits, sample_weight=mask)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    # y_pred dimentions: (batch_size, seq_length, vocab_size)\n",
    "    # y_true dimentions: (batch_size, seq_length)\n",
    "    pred_values = K.cast(K.argmax(y_pred, axis=-1), dtype='int32')\n",
    "    correct = K.cast(K.equal(y_true, pred_values), dtype='float32')\n",
    "\n",
    "    # Masking of values equal to 0, used for padding\n",
    "    mask = K.cast(K.greater(y_true, 0), dtype='float32')\n",
    "    n_correct = K.sum(mask * correct)\n",
    "    n_total = K.sum(mask)\n",
    "  \n",
    "    return n_correct / n_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "* Call to the encoder for each batch of input sequences, the output produced is the encoded vector\n",
    "* Setting the initial state of the decoder equal to the encoded vector\n",
    "* Call to the decoder, passing the target sequence as input starting from the second element to eliminate the <sos> token \n",
    "* Calculation of loss and accuracy for each batch of examples\n",
    "* Update of model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_seq, target_seq_in, target_seq_out, en_initial_states, optimizer):\n",
    "    # We use tf.GradientTape to keep track of gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        en_outputs = encoder(input_seq, en_initial_states)\n",
    "\n",
    "        # Configuration of the decoder state based on the encoder outpu\n",
    "        en_states = en_outputs[1:]\n",
    "        de_states = en_states\n",
    "\n",
    "        de_outputs = decoder(target_seq_in, de_states)\n",
    "\n",
    "        # Logits of the output\n",
    "        logits = de_outputs[0]\n",
    "\n",
    "        loss = loss_func(target_seq_out, logits)\n",
    "        acc = accuracy_fn(target_seq_out, logits)\n",
    "\n",
    "    parameters = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    # Calculation of gradients on the model parameters\n",
    "    gradients = tape.gradient(loss, parameters)\n",
    "\n",
    "    # Correction of the model weights\n",
    "    optimizer.apply_gradients(zip(gradients, parameters))\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training, three sequences are used:\n",
    "\n",
    "* **Input sequence**: An array of integers of size (batch_size, max_seq_len, embedding dim). It is the input sequence to the encoder.\n",
    "\n",
    "* **target sequence**: An array of integers of size (batch_size, max_seq_len, embedding dim). It is the expected output from the model.\n",
    "\n",
    "* **Target input sequence**: An array of integers of size (batch_size, max_seq_len, embedding dim). It is the input sequence to the decoder that utilizes the *Teacher Forcing* method.\n",
    "    \n",
    "        \n",
    "        \n",
    "### Teacher Forcing\n",
    "*Teacher Forcing* is one of the primary training methods in the field of NLP. It is a way to train recurrent architectures quickly. Normally, in recurrent architectures, the input at time step t of a sequence is the output generated by the same model at time step t-1. Instead of the output generated by the model, the predicted output at time step t-1 is used as input for each subsequent time step t. This way, it is possible to improve the learning capabilities of the network.\n",
    "\n",
    "This training technique is highly effective when the output predicted by a model does not vary excessively during training. If a model that is more creative and less conservative is needed, this technique should not be used, or it should be used every so often, in a pseudorandom manner, to contribute to variance in the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to start training\n",
    "def main_train(encoder, decoder, dataset, n_epochs, batch_size, optimizer, checkpoint, checkpoint_prefix):\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "\n",
    "    for e in range(n_epochs):\n",
    "        start = time.time()\n",
    "        # Initialization and retrieval of the initialized state of the encoder\n",
    "        en_initial_states = encoder.init_states(batch_size)\n",
    "\n",
    "        # Loop over all examples one batch at a time\n",
    "        for batch, (input_seq, target_seq_in, target_seq_out) in enumerate(dataset.take(-1)):\n",
    "            # Training and retrieval of metrics\n",
    "            loss, accuracy = train_step(input_seq, target_seq_in, target_seq_out, en_initial_states, optimizer)\n",
    "        \n",
    "            if batch % 100 == 0:\n",
    "                # Storing loss and accuracy every 100 batches for subsequent analysis\n",
    "                losses.append(loss)\n",
    "                accuracies.append(accuracy)\n",
    "                print('Epoch {} Batch {} Loss {:.4f} Acc:{:.4f}'.format(e + 1, batch, loss.numpy(), accuracy.numpy()))\n",
    "                \n",
    "        # Checkpoint (saving state) of the model every 2 epochs\n",
    "        # Given the slowness of training, this allows to recover\n",
    "        # its state at later points after any stoppage,\n",
    "        # enabling to continue training without restarting it from scratch.\n",
    "        if (e + 1) % 2 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "    \n",
    "        print('Time taken for 1\\'epoch {:.4f} sec\\n'.format(time.time() - start))\n",
    "        \n",
    "    return losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 2.6909 Acc:0.0000\n",
      "Epoch 1 Batch 100 Loss 1.3775 Acc:0.3607\n",
      "Epoch 1 Batch 200 Loss 1.2044 Acc:0.3802\n",
      "Epoch 1 Batch 300 Loss 1.1320 Acc:0.3901\n",
      "Epoch 1 Batch 400 Loss 1.1544 Acc:0.3520\n",
      "Epoch 1 Batch 500 Loss 1.1302 Acc:0.3953\n",
      "Epoch 1 Batch 600 Loss 1.0948 Acc:0.4204\n",
      "Epoch 1 Batch 700 Loss 1.0373 Acc:0.4297\n",
      "Epoch 1 Batch 800 Loss 1.0129 Acc:0.4336\n",
      "Epoch 1 Batch 900 Loss 1.0285 Acc:0.4548\n",
      "Epoch 1 Batch 1000 Loss 0.8821 Acc:0.4529\n",
      "Epoch 1 Batch 1100 Loss 0.8049 Acc:0.5114\n",
      "Epoch 1 Batch 1200 Loss 0.7655 Acc:0.5294\n",
      "Epoch 1 Batch 1300 Loss 0.8438 Acc:0.4880\n",
      "Epoch 1 Batch 1400 Loss 0.7748 Acc:0.5450\n",
      "Epoch 1 Batch 1500 Loss 0.7719 Acc:0.5331\n",
      "Time taken for 1 epoch 60.1968 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.7485 Acc:0.5000\n",
      "Epoch 2 Batch 100 Loss 0.6300 Acc:0.5706\n",
      "Epoch 2 Batch 200 Loss 0.6746 Acc:0.5556\n",
      "Epoch 2 Batch 300 Loss 0.6384 Acc:0.5714\n",
      "Epoch 2 Batch 400 Loss 0.6586 Acc:0.5682\n",
      "Epoch 2 Batch 500 Loss 0.6443 Acc:0.5476\n",
      "Epoch 2 Batch 600 Loss 0.6623 Acc:0.5543\n",
      "Epoch 2 Batch 700 Loss 0.6272 Acc:0.5845\n",
      "Epoch 2 Batch 800 Loss 0.6206 Acc:0.5864\n",
      "Epoch 2 Batch 900 Loss 0.5829 Acc:0.5887\n",
      "Epoch 2 Batch 1000 Loss 0.6188 Acc:0.5686\n",
      "Epoch 2 Batch 1100 Loss 0.5230 Acc:0.6246\n",
      "Epoch 2 Batch 1200 Loss 0.5818 Acc:0.5637\n",
      "Epoch 2 Batch 1300 Loss 0.5624 Acc:0.6168\n",
      "Epoch 2 Batch 1400 Loss 0.5187 Acc:0.6402\n",
      "Epoch 2 Batch 1500 Loss 0.5850 Acc:0.6352\n",
      "Time taken for 1 epoch 58.7275 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.4508 Acc:0.6432\n",
      "Epoch 3 Batch 100 Loss 0.4634 Acc:0.6475\n",
      "Epoch 3 Batch 200 Loss 0.4655 Acc:0.6320\n",
      "Epoch 3 Batch 300 Loss 0.4616 Acc:0.6474\n",
      "Epoch 3 Batch 400 Loss 0.4791 Acc:0.6509\n",
      "Epoch 3 Batch 500 Loss 0.3976 Acc:0.6496\n",
      "Epoch 3 Batch 600 Loss 0.4287 Acc:0.6685\n",
      "Epoch 3 Batch 700 Loss 0.4168 Acc:0.6736\n",
      "Epoch 3 Batch 800 Loss 0.4559 Acc:0.6481\n",
      "Epoch 3 Batch 900 Loss 0.4207 Acc:0.6774\n",
      "Epoch 3 Batch 1000 Loss 0.4045 Acc:0.6648\n",
      "Epoch 3 Batch 1100 Loss 0.4190 Acc:0.6320\n",
      "Epoch 3 Batch 1200 Loss 0.4593 Acc:0.6639\n",
      "Epoch 3 Batch 1300 Loss 0.4127 Acc:0.6385\n",
      "Epoch 3 Batch 1400 Loss 0.3963 Acc:0.6896\n",
      "Epoch 3 Batch 1500 Loss 0.3682 Acc:0.6847\n",
      "Time taken for 1 epoch 58.2667 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.3402 Acc:0.6975\n",
      "Epoch 4 Batch 100 Loss 0.3278 Acc:0.7035\n",
      "Epoch 4 Batch 200 Loss 0.3397 Acc:0.7042\n",
      "Epoch 4 Batch 300 Loss 0.3249 Acc:0.7089\n",
      "Epoch 4 Batch 400 Loss 0.3012 Acc:0.7118\n",
      "Epoch 4 Batch 500 Loss 0.3567 Acc:0.7074\n",
      "Epoch 4 Batch 600 Loss 0.3159 Acc:0.7074\n",
      "Epoch 4 Batch 700 Loss 0.3612 Acc:0.6894\n",
      "Epoch 4 Batch 800 Loss 0.2976 Acc:0.7270\n",
      "Epoch 4 Batch 900 Loss 0.3093 Acc:0.7317\n",
      "Epoch 4 Batch 1000 Loss 0.3532 Acc:0.7112\n",
      "Epoch 4 Batch 1100 Loss 0.3184 Acc:0.6863\n",
      "Epoch 4 Batch 1200 Loss 0.3169 Acc:0.7166\n",
      "Epoch 4 Batch 1300 Loss 0.3296 Acc:0.7060\n",
      "Epoch 4 Batch 1400 Loss 0.3544 Acc:0.7029\n",
      "Epoch 4 Batch 1500 Loss 0.3025 Acc:0.7022\n",
      "Time taken for 1 epoch 61.1561 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.2311 Acc:0.7789\n",
      "Epoch 5 Batch 100 Loss 0.2263 Acc:0.7989\n",
      "Epoch 5 Batch 200 Loss 0.2410 Acc:0.7827\n",
      "Epoch 5 Batch 300 Loss 0.2622 Acc:0.7682\n",
      "Epoch 5 Batch 400 Loss 0.2377 Acc:0.7739\n",
      "Epoch 5 Batch 500 Loss 0.2443 Acc:0.7486\n",
      "Epoch 5 Batch 600 Loss 0.2445 Acc:0.7547\n",
      "Epoch 5 Batch 700 Loss 0.2498 Acc:0.7479\n",
      "Epoch 5 Batch 800 Loss 0.2516 Acc:0.7507\n",
      "Epoch 5 Batch 900 Loss 0.2560 Acc:0.7459\n",
      "Epoch 5 Batch 1000 Loss 0.2395 Acc:0.7337\n",
      "Epoch 5 Batch 1100 Loss 0.2683 Acc:0.7527\n",
      "Epoch 5 Batch 1200 Loss 0.2563 Acc:0.7560\n",
      "Epoch 5 Batch 1300 Loss 0.2129 Acc:0.7527\n",
      "Epoch 5 Batch 1400 Loss 0.2271 Acc:0.7548\n",
      "Epoch 5 Batch 1500 Loss 0.2342 Acc:0.7796\n",
      "Time taken for 1 epoch 61.7940 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.2025 Acc:0.7901\n",
      "Epoch 6 Batch 100 Loss 0.1583 Acc:0.8080\n",
      "Epoch 6 Batch 200 Loss 0.1879 Acc:0.8016\n",
      "Epoch 6 Batch 300 Loss 0.1873 Acc:0.7978\n",
      "Epoch 6 Batch 400 Loss 0.2066 Acc:0.7479\n",
      "Epoch 6 Batch 500 Loss 0.2286 Acc:0.7526\n",
      "Epoch 6 Batch 600 Loss 0.1952 Acc:0.7935\n",
      "Epoch 6 Batch 700 Loss 0.1969 Acc:0.7935\n",
      "Epoch 6 Batch 800 Loss 0.2088 Acc:0.7953\n",
      "Epoch 6 Batch 900 Loss 0.2165 Acc:0.7730\n",
      "Epoch 6 Batch 1000 Loss 0.1815 Acc:0.7939\n",
      "Epoch 6 Batch 1100 Loss 0.2019 Acc:0.7808\n",
      "Epoch 6 Batch 1200 Loss 0.2164 Acc:0.7513\n",
      "Epoch 6 Batch 1300 Loss 0.1912 Acc:0.7781\n",
      "Epoch 6 Batch 1400 Loss 0.2066 Acc:0.7711\n",
      "Epoch 6 Batch 1500 Loss 0.1966 Acc:0.7910\n",
      "Time taken for 1 epoch 63.2593 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.1577 Acc:0.8225\n",
      "Epoch 7 Batch 100 Loss 0.1528 Acc:0.8316\n",
      "Epoch 7 Batch 200 Loss 0.1799 Acc:0.7902\n",
      "Epoch 7 Batch 300 Loss 0.1747 Acc:0.7867\n",
      "Epoch 7 Batch 400 Loss 0.1778 Acc:0.8223\n",
      "Epoch 7 Batch 500 Loss 0.1722 Acc:0.7989\n",
      "Epoch 7 Batch 600 Loss 0.1896 Acc:0.7817\n",
      "Epoch 7 Batch 700 Loss 0.1716 Acc:0.8031\n",
      "Epoch 7 Batch 800 Loss 0.1670 Acc:0.8011\n",
      "Epoch 7 Batch 900 Loss 0.1829 Acc:0.7888\n",
      "Epoch 7 Batch 1000 Loss 0.1545 Acc:0.8306\n",
      "Epoch 7 Batch 1100 Loss 0.1853 Acc:0.7898\n",
      "Epoch 7 Batch 1200 Loss 0.1820 Acc:0.7967\n",
      "Epoch 7 Batch 1300 Loss 0.1747 Acc:0.7994\n",
      "Epoch 7 Batch 1400 Loss 0.1630 Acc:0.8099\n",
      "Epoch 7 Batch 1500 Loss 0.1894 Acc:0.8057\n",
      "Time taken for 1 epoch 63.6661 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.1409 Acc:0.8169\n",
      "Epoch 8 Batch 100 Loss 0.1476 Acc:0.8156\n",
      "Epoch 8 Batch 200 Loss 0.1246 Acc:0.8430\n",
      "Epoch 8 Batch 300 Loss 0.1282 Acc:0.8343\n",
      "Epoch 8 Batch 400 Loss 0.1263 Acc:0.8338\n",
      "Epoch 8 Batch 500 Loss 0.1418 Acc:0.8251\n",
      "Epoch 8 Batch 600 Loss 0.1327 Acc:0.8362\n",
      "Epoch 8 Batch 700 Loss 0.1593 Acc:0.7887\n",
      "Epoch 8 Batch 800 Loss 0.1368 Acc:0.8320\n",
      "Epoch 8 Batch 900 Loss 0.1427 Acc:0.8307\n",
      "Epoch 8 Batch 1000 Loss 0.1501 Acc:0.8179\n",
      "Epoch 8 Batch 1100 Loss 0.1435 Acc:0.8192\n",
      "Epoch 8 Batch 1200 Loss 0.1509 Acc:0.8250\n",
      "Epoch 8 Batch 1300 Loss 0.1576 Acc:0.7995\n",
      "Epoch 8 Batch 1400 Loss 0.1582 Acc:0.8149\n",
      "Epoch 8 Batch 1500 Loss 0.1606 Acc:0.7984\n",
      "Time taken for 1 epoch 64.3887 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.1283 Acc:0.8189\n",
      "Epoch 9 Batch 100 Loss 0.1190 Acc:0.8352\n",
      "Epoch 9 Batch 200 Loss 0.1287 Acc:0.8421\n",
      "Epoch 9 Batch 300 Loss 0.1315 Acc:0.8398\n",
      "Epoch 9 Batch 400 Loss 0.1424 Acc:0.8174\n",
      "Epoch 9 Batch 500 Loss 0.1262 Acc:0.8403\n",
      "Epoch 9 Batch 600 Loss 0.1311 Acc:0.8273\n",
      "Epoch 9 Batch 700 Loss 0.1422 Acc:0.8260\n",
      "Epoch 9 Batch 800 Loss 0.1426 Acc:0.7971\n",
      "Epoch 9 Batch 900 Loss 0.1626 Acc:0.7871\n",
      "Epoch 9 Batch 1000 Loss 0.1392 Acc:0.8275\n",
      "Epoch 9 Batch 1100 Loss 0.1521 Acc:0.8315\n",
      "Epoch 9 Batch 1200 Loss 0.1490 Acc:0.8194\n",
      "Epoch 9 Batch 1300 Loss 0.1443 Acc:0.8164\n",
      "Epoch 9 Batch 1400 Loss 0.1275 Acc:0.8411\n",
      "Epoch 9 Batch 1500 Loss 0.1482 Acc:0.8135\n",
      "Time taken for 1 epoch 63.8440 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.1165 Acc:0.8282\n",
      "Epoch 10 Batch 100 Loss 0.1283 Acc:0.8381\n",
      "Epoch 10 Batch 200 Loss 0.1252 Acc:0.8292\n",
      "Epoch 10 Batch 300 Loss 0.1251 Acc:0.8439\n",
      "Epoch 10 Batch 400 Loss 0.1191 Acc:0.8539\n",
      "Epoch 10 Batch 500 Loss 0.1325 Acc:0.8184\n",
      "Epoch 10 Batch 600 Loss 0.1263 Acc:0.8225\n",
      "Epoch 10 Batch 700 Loss 0.1254 Acc:0.8441\n",
      "Epoch 10 Batch 800 Loss 0.1294 Acc:0.8116\n",
      "Epoch 10 Batch 900 Loss 0.1274 Acc:0.8474\n",
      "Epoch 10 Batch 1000 Loss 0.1315 Acc:0.8324\n",
      "Epoch 10 Batch 1100 Loss 0.1577 Acc:0.8142\n",
      "Epoch 10 Batch 1200 Loss 0.1282 Acc:0.8435\n",
      "Epoch 10 Batch 1300 Loss 0.1579 Acc:0.8132\n",
      "Epoch 10 Batch 1400 Loss 0.1489 Acc:0.7863\n",
      "Epoch 10 Batch 1500 Loss 0.1313 Acc:0.8179\n",
      "Time taken for 1 epoch 64.1021 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.1070 Acc:0.8618\n",
      "Epoch 11 Batch 100 Loss 0.1088 Acc:0.8287\n",
      "Epoch 11 Batch 200 Loss 0.1079 Acc:0.8519\n",
      "Epoch 11 Batch 300 Loss 0.1139 Acc:0.8472\n",
      "Epoch 11 Batch 400 Loss 0.1238 Acc:0.8291\n",
      "Epoch 11 Batch 500 Loss 0.1300 Acc:0.8508\n",
      "Epoch 11 Batch 600 Loss 0.1336 Acc:0.8280\n",
      "Epoch 11 Batch 700 Loss 0.1242 Acc:0.8302\n",
      "Epoch 11 Batch 800 Loss 0.1640 Acc:0.8022\n",
      "Epoch 11 Batch 900 Loss 0.1348 Acc:0.8153\n",
      "Epoch 11 Batch 1000 Loss 0.1110 Acc:0.8592\n",
      "Epoch 11 Batch 1100 Loss 0.1217 Acc:0.8238\n",
      "Epoch 11 Batch 1200 Loss 0.1195 Acc:0.8491\n",
      "Epoch 11 Batch 1300 Loss 0.1457 Acc:0.8308\n",
      "Epoch 11 Batch 1400 Loss 0.1196 Acc:0.8466\n",
      "Epoch 11 Batch 1500 Loss 0.1207 Acc:0.8575\n",
      "Time taken for 1 epoch 63.6548 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.1237 Acc:0.8222\n",
      "Epoch 12 Batch 100 Loss 0.0864 Acc:0.8819\n",
      "Epoch 12 Batch 200 Loss 0.0857 Acc:0.8796\n",
      "Epoch 12 Batch 300 Loss 0.1046 Acc:0.8379\n",
      "Epoch 12 Batch 400 Loss 0.1221 Acc:0.8583\n",
      "Epoch 12 Batch 500 Loss 0.1224 Acc:0.8291\n",
      "Epoch 12 Batch 600 Loss 0.1204 Acc:0.8410\n",
      "Epoch 12 Batch 700 Loss 0.1334 Acc:0.8090\n",
      "Epoch 12 Batch 800 Loss 0.0997 Acc:0.8528\n",
      "Epoch 12 Batch 900 Loss 0.1308 Acc:0.8128\n",
      "Epoch 12 Batch 1000 Loss 0.1254 Acc:0.8287\n",
      "Epoch 12 Batch 1100 Loss 0.1232 Acc:0.8310\n",
      "Epoch 12 Batch 1200 Loss 0.1374 Acc:0.8245\n",
      "Epoch 12 Batch 1300 Loss 0.1249 Acc:0.8311\n",
      "Epoch 12 Batch 1400 Loss 0.1176 Acc:0.8379\n",
      "Epoch 12 Batch 1500 Loss 0.1369 Acc:0.8280\n",
      "Time taken for 1 epoch 64.9050 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.0881 Acc:0.8676\n",
      "Epoch 13 Batch 100 Loss 0.0994 Acc:0.8607\n",
      "Epoch 13 Batch 200 Loss 0.1011 Acc:0.8587\n",
      "Epoch 13 Batch 300 Loss 0.1008 Acc:0.8459\n",
      "Epoch 13 Batch 400 Loss 0.0946 Acc:0.8681\n",
      "Epoch 13 Batch 500 Loss 0.1197 Acc:0.8495\n",
      "Epoch 13 Batch 600 Loss 0.1087 Acc:0.8449\n",
      "Epoch 13 Batch 700 Loss 0.1162 Acc:0.8408\n",
      "Epoch 13 Batch 800 Loss 0.1084 Acc:0.8488\n",
      "Epoch 13 Batch 900 Loss 0.1073 Acc:0.8549\n",
      "Epoch 13 Batch 1000 Loss 0.0984 Acc:0.8708\n",
      "Epoch 13 Batch 1100 Loss 0.1176 Acc:0.8192\n",
      "Epoch 13 Batch 1200 Loss 0.1105 Acc:0.8240\n",
      "Epoch 13 Batch 1300 Loss 0.1321 Acc:0.8083\n",
      "Epoch 13 Batch 1400 Loss 0.1177 Acc:0.8424\n",
      "Epoch 13 Batch 1500 Loss 0.1330 Acc:0.8059\n",
      "Time taken for 1 epoch 64.0732 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.1081 Acc:0.8559\n",
      "Epoch 14 Batch 100 Loss 0.0906 Acc:0.8556\n",
      "Epoch 14 Batch 200 Loss 0.1018 Acc:0.8497\n",
      "Epoch 14 Batch 300 Loss 0.0990 Acc:0.8638\n",
      "Epoch 14 Batch 400 Loss 0.1098 Acc:0.8220\n",
      "Epoch 14 Batch 500 Loss 0.1060 Acc:0.8423\n",
      "Epoch 14 Batch 600 Loss 0.1101 Acc:0.8381\n",
      "Epoch 14 Batch 700 Loss 0.1022 Acc:0.8401\n",
      "Epoch 14 Batch 800 Loss 0.1106 Acc:0.8397\n",
      "Epoch 14 Batch 900 Loss 0.1134 Acc:0.8315\n",
      "Epoch 14 Batch 1000 Loss 0.1206 Acc:0.8440\n",
      "Epoch 14 Batch 1100 Loss 0.1090 Acc:0.8501\n",
      "Epoch 14 Batch 1200 Loss 0.1105 Acc:0.8451\n",
      "Epoch 14 Batch 1300 Loss 0.1145 Acc:0.8497\n",
      "Epoch 14 Batch 1400 Loss 0.1363 Acc:0.8085\n",
      "Epoch 14 Batch 1500 Loss 0.1100 Acc:0.8283\n",
      "Time taken for 1 epoch 64.2915 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.0879 Acc:0.8839\n",
      "Epoch 15 Batch 100 Loss 0.0907 Acc:0.8671\n",
      "Epoch 15 Batch 200 Loss 0.0907 Acc:0.8654\n",
      "Epoch 15 Batch 300 Loss 0.0999 Acc:0.8523\n",
      "Epoch 15 Batch 400 Loss 0.1047 Acc:0.8719\n",
      "Epoch 15 Batch 500 Loss 0.0875 Acc:0.8661\n",
      "Epoch 15 Batch 600 Loss 0.1224 Acc:0.8311\n",
      "Epoch 15 Batch 700 Loss 0.1149 Acc:0.8177\n",
      "Epoch 15 Batch 800 Loss 0.1093 Acc:0.8544\n",
      "Epoch 15 Batch 900 Loss 0.1033 Acc:0.8378\n",
      "Epoch 15 Batch 1000 Loss 0.1063 Acc:0.8534\n",
      "Epoch 15 Batch 1100 Loss 0.1140 Acc:0.8397\n",
      "Epoch 15 Batch 1200 Loss 0.1068 Acc:0.8540\n",
      "Epoch 15 Batch 1300 Loss 0.1166 Acc:0.8545\n",
      "Epoch 15 Batch 1400 Loss 0.1103 Acc:0.8187\n",
      "Epoch 15 Batch 1500 Loss 0.1059 Acc:0.8353\n",
      "Time taken for 1 epoch 64.9095 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0888 Acc:0.8670\n",
      "Epoch 16 Batch 100 Loss 0.0859 Acc:0.8726\n",
      "Epoch 16 Batch 200 Loss 0.0957 Acc:0.8757\n",
      "Epoch 16 Batch 300 Loss 0.1033 Acc:0.8516\n",
      "Epoch 16 Batch 400 Loss 0.1025 Acc:0.8540\n",
      "Epoch 16 Batch 500 Loss 0.0890 Acc:0.8767\n",
      "Epoch 16 Batch 600 Loss 0.1086 Acc:0.8287\n",
      "Epoch 16 Batch 700 Loss 0.1045 Acc:0.8184\n",
      "Epoch 16 Batch 800 Loss 0.1273 Acc:0.8403\n",
      "Epoch 16 Batch 900 Loss 0.0859 Acc:0.8568\n",
      "Epoch 16 Batch 1000 Loss 0.0932 Acc:0.8591\n",
      "Epoch 16 Batch 1100 Loss 0.1044 Acc:0.8514\n",
      "Epoch 16 Batch 1200 Loss 0.1089 Acc:0.8280\n",
      "Epoch 16 Batch 1300 Loss 0.1225 Acc:0.8414\n",
      "Epoch 16 Batch 1400 Loss 0.1184 Acc:0.8167\n",
      "Epoch 16 Batch 1500 Loss 0.1225 Acc:0.8263\n",
      "Time taken for 1 epoch 64.8951 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0941 Acc:0.8704\n",
      "Epoch 17 Batch 100 Loss 0.0902 Acc:0.8726\n",
      "Epoch 17 Batch 200 Loss 0.1013 Acc:0.8451\n",
      "Epoch 17 Batch 300 Loss 0.0898 Acc:0.8407\n",
      "Epoch 17 Batch 400 Loss 0.0956 Acc:0.8556\n",
      "Epoch 17 Batch 500 Loss 0.1031 Acc:0.8484\n",
      "Epoch 17 Batch 600 Loss 0.0859 Acc:0.8760\n",
      "Epoch 17 Batch 700 Loss 0.1149 Acc:0.8289\n",
      "Epoch 17 Batch 800 Loss 0.1176 Acc:0.8275\n",
      "Epoch 17 Batch 900 Loss 0.1069 Acc:0.8431\n",
      "Epoch 17 Batch 1000 Loss 0.1109 Acc:0.8443\n",
      "Epoch 17 Batch 1100 Loss 0.1047 Acc:0.8449\n",
      "Epoch 17 Batch 1200 Loss 0.1037 Acc:0.8579\n",
      "Epoch 17 Batch 1300 Loss 0.0998 Acc:0.8177\n",
      "Epoch 17 Batch 1400 Loss 0.1037 Acc:0.8567\n",
      "Epoch 17 Batch 1500 Loss 0.1093 Acc:0.8267\n",
      "Time taken for 1 epoch 65.0838 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0863 Acc:0.8639\n",
      "Epoch 18 Batch 100 Loss 0.0750 Acc:0.8782\n",
      "Epoch 18 Batch 200 Loss 0.0879 Acc:0.8771\n",
      "Epoch 18 Batch 300 Loss 0.0902 Acc:0.8447\n",
      "Epoch 18 Batch 400 Loss 0.1052 Acc:0.8514\n",
      "Epoch 18 Batch 500 Loss 0.0994 Acc:0.8556\n",
      "Epoch 18 Batch 600 Loss 0.1104 Acc:0.8421\n",
      "Epoch 18 Batch 700 Loss 0.0981 Acc:0.8579\n",
      "Epoch 18 Batch 800 Loss 0.0805 Acc:0.8705\n",
      "Epoch 18 Batch 900 Loss 0.0972 Acc:0.8603\n",
      "Epoch 18 Batch 1000 Loss 0.1015 Acc:0.8459\n",
      "Epoch 18 Batch 1100 Loss 0.1044 Acc:0.8407\n",
      "Epoch 18 Batch 1200 Loss 0.1053 Acc:0.8455\n",
      "Epoch 18 Batch 1300 Loss 0.1185 Acc:0.7977\n",
      "Epoch 18 Batch 1400 Loss 0.0955 Acc:0.8799\n",
      "Epoch 18 Batch 1500 Loss 0.0973 Acc:0.8440\n",
      "Time taken for 1 epoch 65.0582 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0849 Acc:0.8696\n",
      "Epoch 19 Batch 100 Loss 0.1050 Acc:0.8459\n",
      "Epoch 19 Batch 200 Loss 0.1181 Acc:0.8268\n",
      "Epoch 19 Batch 300 Loss 0.0814 Acc:0.8734\n",
      "Epoch 19 Batch 400 Loss 0.0806 Acc:0.8827\n",
      "Epoch 19 Batch 500 Loss 0.1028 Acc:0.8249\n",
      "Epoch 19 Batch 600 Loss 0.1039 Acc:0.8172\n",
      "Epoch 19 Batch 700 Loss 0.0991 Acc:0.8306\n",
      "Epoch 19 Batch 800 Loss 0.1116 Acc:0.8135\n",
      "Epoch 19 Batch 900 Loss 0.1151 Acc:0.8215\n",
      "Epoch 19 Batch 1000 Loss 0.0964 Acc:0.8459\n",
      "Epoch 19 Batch 1100 Loss 0.0973 Acc:0.8707\n",
      "Epoch 19 Batch 1200 Loss 0.0949 Acc:0.8815\n",
      "Epoch 19 Batch 1300 Loss 0.1199 Acc:0.8286\n",
      "Epoch 19 Batch 1400 Loss 0.1037 Acc:0.8495\n",
      "Epoch 19 Batch 1500 Loss 0.1064 Acc:0.8615\n",
      "Time taken for 1 epoch 65.3343 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0729 Acc:0.8795\n",
      "Epoch 20 Batch 100 Loss 0.0869 Acc:0.8472\n",
      "Epoch 20 Batch 200 Loss 0.0905 Acc:0.8559\n",
      "Epoch 20 Batch 300 Loss 0.1026 Acc:0.8245\n",
      "Epoch 20 Batch 400 Loss 0.0940 Acc:0.8357\n",
      "Epoch 20 Batch 500 Loss 0.0822 Acc:0.8634\n",
      "Epoch 20 Batch 600 Loss 0.0879 Acc:0.8324\n",
      "Epoch 20 Batch 700 Loss 0.0798 Acc:0.8691\n",
      "Epoch 20 Batch 800 Loss 0.0934 Acc:0.8516\n",
      "Epoch 20 Batch 900 Loss 0.0988 Acc:0.8521\n",
      "Epoch 20 Batch 1000 Loss 0.0960 Acc:0.8525\n",
      "Epoch 20 Batch 1100 Loss 0.0981 Acc:0.8571\n",
      "Epoch 20 Batch 1200 Loss 0.1039 Acc:0.8316\n",
      "Epoch 20 Batch 1300 Loss 0.1021 Acc:0.8258\n",
      "Epoch 20 Batch 1400 Loss 0.1007 Acc:0.8283\n",
      "Epoch 20 Batch 1500 Loss 0.1056 Acc:0.8240\n",
      "Time taken for 1 epoch 66.5145 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.0734 Acc:0.8895\n",
      "Epoch 21 Batch 100 Loss 0.0885 Acc:0.8536\n",
      "Epoch 21 Batch 200 Loss 0.0866 Acc:0.8727\n",
      "Epoch 21 Batch 300 Loss 0.0890 Acc:0.8703\n",
      "Epoch 21 Batch 400 Loss 0.0924 Acc:0.8677\n",
      "Epoch 21 Batch 500 Loss 0.1093 Acc:0.8386\n",
      "Epoch 21 Batch 600 Loss 0.0866 Acc:0.8681\n",
      "Epoch 21 Batch 700 Loss 0.1012 Acc:0.8480\n",
      "Epoch 21 Batch 800 Loss 0.0958 Acc:0.8351\n",
      "Epoch 21 Batch 900 Loss 0.1066 Acc:0.8361\n",
      "Epoch 21 Batch 1000 Loss 0.0888 Acc:0.8715\n",
      "Epoch 21 Batch 1100 Loss 0.1003 Acc:0.8447\n",
      "Epoch 21 Batch 1200 Loss 0.0956 Acc:0.8615\n",
      "Epoch 21 Batch 1300 Loss 0.0888 Acc:0.8607\n",
      "Epoch 21 Batch 1400 Loss 0.1002 Acc:0.8431\n",
      "Epoch 21 Batch 1500 Loss 0.1133 Acc:0.8319\n",
      "Time taken for 1 epoch 66.0206 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.0793 Acc:0.8737\n",
      "Epoch 22 Batch 100 Loss 0.0877 Acc:0.8522\n",
      "Epoch 22 Batch 200 Loss 0.0701 Acc:0.8790\n",
      "Epoch 22 Batch 300 Loss 0.0874 Acc:0.8607\n",
      "Epoch 22 Batch 400 Loss 0.0882 Acc:0.8390\n",
      "Epoch 22 Batch 500 Loss 0.0921 Acc:0.8603\n",
      "Epoch 22 Batch 600 Loss 0.0842 Acc:0.8466\n",
      "Epoch 22 Batch 700 Loss 0.1063 Acc:0.8365\n",
      "Epoch 22 Batch 800 Loss 0.0914 Acc:0.8470\n",
      "Epoch 22 Batch 900 Loss 0.0933 Acc:0.8437\n",
      "Epoch 22 Batch 1000 Loss 0.0954 Acc:0.8595\n",
      "Epoch 22 Batch 1100 Loss 0.0990 Acc:0.8474\n",
      "Epoch 22 Batch 1200 Loss 0.1020 Acc:0.8596\n",
      "Epoch 22 Batch 1300 Loss 0.0782 Acc:0.8840\n",
      "Epoch 22 Batch 1400 Loss 0.1109 Acc:0.8161\n",
      "Epoch 22 Batch 1500 Loss 0.1075 Acc:0.8301\n",
      "Time taken for 1 epoch 67.1008 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.0780 Acc:0.8630\n",
      "Epoch 23 Batch 100 Loss 0.0856 Acc:0.8584\n",
      "Epoch 23 Batch 200 Loss 0.0730 Acc:0.8736\n",
      "Epoch 23 Batch 300 Loss 0.0874 Acc:0.8753\n",
      "Epoch 23 Batch 400 Loss 0.0755 Acc:0.8700\n",
      "Epoch 23 Batch 500 Loss 0.0997 Acc:0.8388\n",
      "Epoch 23 Batch 600 Loss 0.0984 Acc:0.8474\n",
      "Epoch 23 Batch 700 Loss 0.0932 Acc:0.8342\n",
      "Epoch 23 Batch 800 Loss 0.0945 Acc:0.8324\n",
      "Epoch 23 Batch 900 Loss 0.0898 Acc:0.8536\n",
      "Epoch 23 Batch 1000 Loss 0.1008 Acc:0.8145\n",
      "Epoch 23 Batch 1100 Loss 0.1001 Acc:0.8028\n",
      "Epoch 23 Batch 1200 Loss 0.0957 Acc:0.8434\n",
      "Epoch 23 Batch 1300 Loss 0.1000 Acc:0.8177\n",
      "Epoch 23 Batch 1400 Loss 0.1056 Acc:0.8250\n",
      "Epoch 23 Batch 1500 Loss 0.1028 Acc:0.8307\n",
      "Time taken for 1 epoch 65.8092 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.0763 Acc:0.8846\n",
      "Epoch 24 Batch 100 Loss 0.0855 Acc:0.8440\n",
      "Epoch 24 Batch 200 Loss 0.0896 Acc:0.8547\n",
      "Epoch 24 Batch 300 Loss 0.0797 Acc:0.8384\n",
      "Epoch 24 Batch 400 Loss 0.0992 Acc:0.8468\n",
      "Epoch 24 Batch 500 Loss 0.0972 Acc:0.8515\n",
      "Epoch 24 Batch 600 Loss 0.0947 Acc:0.8646\n",
      "Epoch 24 Batch 700 Loss 0.0891 Acc:0.8583\n",
      "Epoch 24 Batch 800 Loss 0.0873 Acc:0.8583\n",
      "Epoch 24 Batch 900 Loss 0.1040 Acc:0.8411\n",
      "Epoch 24 Batch 1000 Loss 0.0955 Acc:0.8491\n",
      "Epoch 24 Batch 1100 Loss 0.1010 Acc:0.8394\n",
      "Epoch 24 Batch 1200 Loss 0.0922 Acc:0.8635\n",
      "Epoch 24 Batch 1300 Loss 0.1115 Acc:0.8204\n",
      "Epoch 24 Batch 1400 Loss 0.0977 Acc:0.8333\n",
      "Epoch 24 Batch 1500 Loss 0.1067 Acc:0.8280\n",
      "Time taken for 1 epoch 66.8148 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.0836 Acc:0.8622\n",
      "Epoch 25 Batch 100 Loss 0.0769 Acc:0.8665\n",
      "Epoch 25 Batch 200 Loss 0.0748 Acc:0.8827\n",
      "Epoch 25 Batch 300 Loss 0.1020 Acc:0.8415\n",
      "Epoch 25 Batch 400 Loss 0.0820 Acc:0.8557\n",
      "Epoch 25 Batch 500 Loss 0.0808 Acc:0.8630\n",
      "Epoch 25 Batch 600 Loss 0.0820 Acc:0.8713\n",
      "Epoch 25 Batch 700 Loss 0.0767 Acc:0.8895\n",
      "Epoch 25 Batch 800 Loss 0.0940 Acc:0.8417\n",
      "Epoch 25 Batch 900 Loss 0.0894 Acc:0.8544\n",
      "Epoch 25 Batch 1000 Loss 0.0854 Acc:0.8560\n",
      "Epoch 25 Batch 1100 Loss 0.1115 Acc:0.8132\n",
      "Epoch 25 Batch 1200 Loss 0.1035 Acc:0.8211\n",
      "Epoch 25 Batch 1300 Loss 0.1034 Acc:0.8324\n",
      "Epoch 25 Batch 1400 Loss 0.0984 Acc:0.8575\n",
      "Epoch 25 Batch 1500 Loss 0.0875 Acc:0.8329\n",
      "Time taken for 1 epoch 66.4619 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setting Adam as optimizer with the parameter [clipnorm] set to 5 to enable L2 regularization of gradients \n",
    "# when their average exceeds this value - limits potential gradient explosion phenomena and \n",
    "# restrains radical weight changes, allowing for better generalization.\n",
    "optimizer = tf.keras.optimizers.Adam(clipnorm=5.0)\n",
    "\n",
    "# Creation of an initial checkpoint for the newly created model\n",
    "checkpoint_dir = './seq2seq'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n",
    "\n",
    "# Start training with previously set hyperparameters\n",
    "losses, accuracies = main_train(encoder, decoder, dataset, EPOCHS, BATCH_SIZE, optimizer, checkpoint, checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of training\n",
    "With the output log and training results, we can visualize this information regarding the metrics of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
    "\n",
    "ax1.plot(losses, label='loss')\n",
    "ax1.set_title('Training Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(accuracies, label='acc')\n",
    "ax2.set_title('Training Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "The following cell allows loading the last checkpoint of the previously saved training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x17bc9db6190>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the latest available checkpoint\n",
    "checkpoint_dir = './seq2seq'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a prediction, you must provide a sequence of length 1 containing the sos (start-of-sentence) token. Then, it is possible to call the encoder and decoder repeatedly until you receive the eos (end-of-sentence) token or reach the maximum length limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_text, encoder, input_max_len, tokenizer_inputs, word2idx_outputs, idx2word_outputs):\n",
    "    if input_text is None:\n",
    "        input_text = input_data[np.random.choice(len(input_data))]\n",
    "        print(input_text)\n",
    "    # Tokenization of the input sequence\n",
    "    input_seq = tokenizer_inputs.texts_to_sequences([input_text])\n",
    "    # Padding of the input sequence\n",
    "    input_seq = pad_sequences(input_seq, maxlen=input_max_len, padding='post')\n",
    "    print(input_seq)\n",
    "\n",
    "    # Initialization of encoder states\n",
    "    en_initial_states = encoder.init_states(1)\n",
    "    en_outputs = encoder(tf.constant(input_seq), en_initial_states)\n",
    "    # Creation of input to the decoder, using the <start-of-sentence> token\n",
    "    de_input = tf.constant([[word2idx_outputs['<sos>']]])\n",
    "    # Setting the decoder states to the output states from the encoder\n",
    "    # Set the decoder states to the encoder vector or encoder hidden state\n",
    "    de_state_h, de_state_c = en_outputs[1:]\n",
    "    \n",
    "    out_words = []\n",
    "    while True:\n",
    "        # Decoding and retrieval of output probabilities\n",
    "        de_output, de_state_h, de_state_c = decoder(\n",
    "            de_input, (de_state_h, de_state_c))\n",
    "        # Selection of the most probable word\n",
    "        de_input = tf.argmax(de_output, -1)\n",
    "        # Insertion of the word into the output sequence\n",
    "        out_words.append(idx2word_outputs[de_input.numpy()[0][0]])\n",
    "        # Termination of the loop when the <end-of-sentence> token is encountered\n",
    "        # or when the maximum expected sequence length is reached\n",
    "        if out_words[-1] == '<eos>' or len(out_words) >= 20:\n",
    "            break\n",
    "\n",
    "    print(' '.join(out_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model using some examples taken from the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['do it . ', 'tom came . ', 'they re mine . ', 'you re old . ', 'tom was selected . ']\n",
      "[[16  6  1  0  0  0  0  0  0]]\n",
      "fallo . <eos>\n",
      "[[  4 156   1   0   0   0   0   0   0]]\n",
      "tom e venuto . <eos>\n",
      "[[ 23  10 225   1   0   0   0   0   0]]\n",
      "sono mie . <eos>\n",
      "[[  3  10 152   1   0   0   0   0   0]]\n",
      "voi siete vecchi . <eos>\n",
      "[[   4   20 1337    1    0    0    0    0    0]]\n",
      "tom e stato selezionato . <eos>\n"
     ]
    }
   ],
   "source": [
    "test_sequences = [input_data[42], input_data[1042], input_data[10042], input_data[4242], input_data[42042]]\n",
    "\n",
    "for test_sequence in test_sequences:\n",
    "    print(test_sequence)\n",
    "    predict(test_sequence, encoder, input_max_len, tokenizer_inputs, word2idx_outputs, idx2word_outputs)\n",
    "    print('  -----------------  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
